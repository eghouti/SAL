# Shift Attention Layer 
This is pytorch implementation of Shift Attention Layers (SALs) described in the paper "Attention Based Pruning for Shift Networks" https://arxiv.org/pdf/1905.12300.pdf, an alternative to Convlutional layers. 
